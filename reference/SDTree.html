<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>Spectrally Deconfounded Tree — SDTree • SDModels</title><!-- favicons --><link rel="icon" type="image/png" sizes="48x48" href="../favicon-48x48.png"><link rel="icon" type="”image/svg+xml”" href="../favicon.svg"><link rel="apple-touch-icon" sizes="180x180" href="../apple-touch-icon.png"><link rel="icon" sizes="any" href="../favicon.ico"><link rel="manifest" href="../site.webmanifest"><!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.1/jquery.min.js" integrity="sha512-v2CJ7UaYy4JwqLDIrZUI/4hqeoQieOmAZNXBeQyjo21dadnwR+8ZaIJVT8EE2iyI61OV8e6M8PP2/4hpQINQ/g==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous"><script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css"><script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous"><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet"><script src="../pkgdown.js"></script><meta property="og:title" content="Spectrally Deconfounded Tree — SDTree"><meta property="og:description" content="Estimates a regression tree using spectral deconfounding.
A regression tree is part of the function class of step functions
\(f(X) = \sum_{m = 1}^M 1_{\{X \in R_m\}} c_m\), where (\(R_m\)) with
\(m = 1, \ldots, M\) are regions dividing the space of \(\mathbb{R}^p\)
into \(M\) rectangular parts. Each region has response level \(c_m \in \mathbb{R}\).
For the training data, we can write the step function as \(f(\mathbf{X}) = \mathcal{P} c\)
where \(\mathcal{P} \in \{0, 1\}^{n \times M}\) is an indicator matrix encoding
to which region an observation belongs and \(c \in \mathbb{R}^M\) is a vector
containing the levels corresponding to the different regions. This function then minimizes
$$(\hat{\mathcal{P}}, \hat{c}) = \text{argmin}_{\mathcal{P}' \in \{0, 1\}^{n \times M}, c' \in \mathbb{R}^ {M}} \frac{||Q(\mathbf{Y} - \mathcal{P'} c')||_2^2}{n}$$
We find \(\hat{\mathcal{P}}\) by using the tree structure and repeated splitting of the leaves,
similar to the original cart algorithm (Breiman et al. 2017)
.
Since comparing all possibilities for \(\mathcal{P}\) is impossible, we let a tree grow greedily.
Given the current tree, we iterate over all leaves and all possible splits.
We choose the one that reduces the spectral loss the most and estimate after each split
all the leaf estimates
\(\hat{c} = \text{argmin}_{c' \in \mathbb{R}^M} \frac{||Q\mathbf{Y} - Q\mathcal{P} c'||_2^2}{n}\)
which is just a linear regression problem. This is repeated until the loss decreases
less than a minimum loss decrease after a split.
The minimum loss decrease equals a cost-complexity parameter \(cp\) times
the initial loss when only an overall mean is estimated.
The cost-complexity parameter \(cp\) controls the complexity of a regression tree
and acts as a regularization parameter."><meta property="og:image" content="https://markusul.github.io/SDModels/logo.png"><!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--></head><body data-spy="scroll" data-target="#toc">


    <div class="container template-reference-topic">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">SDModels</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">2.0.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav"><li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Articles

    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu"><li>
      <a href="../articles/AnchorForest.html">AnchorForest</a>
    </li>
    <li>
      <a href="../articles/Runtime.html">Runtime</a>
    </li>
    <li>
      <a href="../articles/SDAM.html">SDAM</a>
    </li>
    <li>
      <a href="../articles/SDForest.html">SDForest</a>
    </li>
    <li>
      <a href="../articles/SDTree.html">SDTree</a>
    </li>
  </ul></li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul><ul class="nav navbar-nav navbar-right"><li>
  <a href="https://github.com/markusul/SDModels/" class="external-link">
    <span class="fab fa-github fa-lg"></span>

  </a>
</li>
      </ul></div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->



      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Spectrally Deconfounded Tree</h1>
    <small class="dont-index">Source: <a href="https://github.com/markusul/SDModels/blob/main/R/SDTree.R" class="external-link"><code>R/SDTree.R</code></a></small>
    <div class="hidden name"><code>SDTree.Rd</code></div>
    </div>

    <div class="ref-description">
    <p>Estimates a regression tree using spectral deconfounding.
A regression tree is part of the function class of step functions
\(f(X) = \sum_{m = 1}^M 1_{\{X \in R_m\}} c_m\), where (\(R_m\)) with
\(m = 1, \ldots, M\) are regions dividing the space of \(\mathbb{R}^p\)
into \(M\) rectangular parts. Each region has response level \(c_m \in \mathbb{R}\).
For the training data, we can write the step function as \(f(\mathbf{X}) = \mathcal{P} c\)
where \(\mathcal{P} \in \{0, 1\}^{n \times M}\) is an indicator matrix encoding
to which region an observation belongs and \(c \in \mathbb{R}^M\) is a vector
containing the levels corresponding to the different regions. This function then minimizes
$$(\hat{\mathcal{P}}, \hat{c}) = \text{argmin}_{\mathcal{P}' \in \{0, 1\}^{n \times M}, c' \in \mathbb{R}^ {M}} \frac{||Q(\mathbf{Y} - \mathcal{P'} c')||_2^2}{n}$$
We find \(\hat{\mathcal{P}}\) by using the tree structure and repeated splitting of the leaves,
similar to the original cart algorithm (Breiman et al. 2017)
.
Since comparing all possibilities for \(\mathcal{P}\) is impossible, we let a tree grow greedily.
Given the current tree, we iterate over all leaves and all possible splits.
We choose the one that reduces the spectral loss the most and estimate after each split
all the leaf estimates
\(\hat{c} = \text{argmin}_{c' \in \mathbb{R}^M} \frac{||Q\mathbf{Y} - Q\mathcal{P} c'||_2^2}{n}\)
which is just a linear regression problem. This is repeated until the loss decreases
less than a minimum loss decrease after a split.
The minimum loss decrease equals a cost-complexity parameter \(cp\) times
the initial loss when only an overall mean is estimated.
The cost-complexity parameter \(cp\) controls the complexity of a regression tree
and acts as a regularization parameter.</p>
    </div>

    <div id="ref-usage">
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">SDTree</span><span class="op">(</span></span>
<span>  formula <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  data <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  x <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  y <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  max_leaves <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  cp <span class="op">=</span> <span class="fl">0.01</span>,</span>
<span>  min_sample <span class="op">=</span> <span class="fl">5</span>,</span>
<span>  mtry <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  fast <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  Q_type <span class="op">=</span> <span class="st">"trim"</span>,</span>
<span>  trim_quantile <span class="op">=</span> <span class="fl">0.5</span>,</span>
<span>  q_hat <span class="op">=</span> <span class="fl">0</span>,</span>
<span>  Qf <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  A <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  gamma <span class="op">=</span> <span class="fl">0.5</span>,</span>
<span>  max_candidates <span class="op">=</span> <span class="fl">100</span>,</span>
<span>  Q_scale <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  predictors <span class="op">=</span> <span class="cn">NULL</span></span>
<span><span class="op">)</span></span></code></pre></div>
    </div>

    <div id="arguments">
    <h2>Arguments</h2>


<dl><dt id="arg-formula">formula<a class="anchor" aria-label="anchor" href="#arg-formula"></a></dt>
<dd><p>Object of class <code>formula</code> or describing the model to fit
of the form <code>y ~ x1 + x2 + ...</code> where <code>y</code> is a numeric response and
<code>x1, x2, ...</code> are vectors of covariates. Interactions are not supported.</p></dd>


<dt id="arg-data">data<a class="anchor" aria-label="anchor" href="#arg-data"></a></dt>
<dd><p>Training data of class <code>data.frame</code> containing the variables in the model.</p></dd>


<dt id="arg-x">x<a class="anchor" aria-label="anchor" href="#arg-x"></a></dt>
<dd><p>Matrix of covariates, alternative to <code>formula</code> and <code>data</code>.</p></dd>


<dt id="arg-y">y<a class="anchor" aria-label="anchor" href="#arg-y"></a></dt>
<dd><p>Vector of responses, alternative to <code>formula</code> and <code>data</code>.</p></dd>


<dt id="arg-max-leaves">max_leaves<a class="anchor" aria-label="anchor" href="#arg-max-leaves"></a></dt>
<dd><p>Maximum number of leaves for the grown tree.</p></dd>


<dt id="arg-cp">cp<a class="anchor" aria-label="anchor" href="#arg-cp"></a></dt>
<dd><p>Complexity parameter, minimum loss decrease to split a node.
A split is only performed if the loss decrease is larger than <code>cp * initial_loss</code>,
where <code>initial_loss</code> is the loss of the initial estimate using only a stump.</p></dd>


<dt id="arg-min-sample">min_sample<a class="anchor" aria-label="anchor" href="#arg-min-sample"></a></dt>
<dd><p>Minimum number of observations per leaf.
A split is only performed if both resulting leaves have at least
<code>min_sample</code> observations.</p></dd>


<dt id="arg-mtry">mtry<a class="anchor" aria-label="anchor" href="#arg-mtry"></a></dt>
<dd><p>Number of randomly selected covariates to consider for a split,
if <code>NULL</code> all covariates are available for each split.</p></dd>


<dt id="arg-fast">fast<a class="anchor" aria-label="anchor" href="#arg-fast"></a></dt>
<dd><p>If <code>TRUE</code>, only the optimal splits in the new leaves are
evaluated and the previously optimal splits and their potential loss-decrease are reused.
If <code>FALSE</code> all possible splits in all the leaves are reevaluated after every split.</p></dd>


<dt id="arg-q-type">Q_type<a class="anchor" aria-label="anchor" href="#arg-q-type"></a></dt>
<dd><p>Type of deconfounding, one of 'trim', 'pca', 'no_deconfounding'.
'trim' corresponds to the Trim transform (Ćevid et al. 2020)

as implemented in the Doubly debiased lasso (Guo et al. 2022)
,
'pca' to the PCA transformation(Paul et al. 2008)
.
See <code><a href="get_Q.html">get_Q</a></code>.</p></dd>


<dt id="arg-trim-quantile">trim_quantile<a class="anchor" aria-label="anchor" href="#arg-trim-quantile"></a></dt>
<dd><p>Quantile for Trim transform,
only needed for trim, see <code><a href="get_Q.html">get_Q</a></code>.</p></dd>


<dt id="arg-q-hat">q_hat<a class="anchor" aria-label="anchor" href="#arg-q-hat"></a></dt>
<dd><p>Assumed confounding dimension, only needed for pca,
see <code><a href="get_Q.html">get_Q</a></code>.</p></dd>


<dt id="arg-qf">Qf<a class="anchor" aria-label="anchor" href="#arg-qf"></a></dt>
<dd><p>Spectral transformation, if <code>NULL</code>
it is internally estimated using <code><a href="get_Q.html">get_Q</a></code>.</p></dd>


<dt id="arg-a">A<a class="anchor" aria-label="anchor" href="#arg-a"></a></dt>
<dd><p>Numerical Anchor of class <code>matrix</code>. See <code><a href="get_W.html">get_W</a></code>.</p></dd>


<dt id="arg-gamma">gamma<a class="anchor" aria-label="anchor" href="#arg-gamma"></a></dt>
<dd><p>Strength of distributional robustness, \(\gamma \in [0, \infty]\).
See <code><a href="get_W.html">get_W</a></code>.</p></dd>


<dt id="arg-max-candidates">max_candidates<a class="anchor" aria-label="anchor" href="#arg-max-candidates"></a></dt>
<dd><p>Maximum number of split points that are
proposed at each node for each covariate.</p></dd>


<dt id="arg-q-scale">Q_scale<a class="anchor" aria-label="anchor" href="#arg-q-scale"></a></dt>
<dd><p>Should data be scaled to estimate the spectral transformation?
Default is <code>TRUE</code> to not reduce the signal of high variance covariates,
and we do not know of a scenario where this hurts.</p></dd>


<dt id="arg-predictors">predictors<a class="anchor" aria-label="anchor" href="#arg-predictors"></a></dt>
<dd><p>Subset of colnames(X) or numerical indices of the covariates
for which an effect on y should be estimated. All the other covariates are only
used for deconfounding.</p></dd>

</dl></div>
    <div id="value">
    <h2>Value</h2>
    <p>Object of class <code>SDTree</code> containing</p>
<dl><dt>predictions</dt>
<dd><p>Predictions for the training set.</p></dd>

<dt>tree</dt>
<dd><p>The estimated tree of class <code>matrix</code>.
The tree contains the information about all the splits and the resulting estimates.</p></dd>

<dt>var_names</dt>
<dd><p>Names of the covariates in the training data.</p></dd>

<dt>var_importance</dt>
<dd><p>Variable importance of the covariates.
The variable importance is calculated as the sum of the decrease in the loss
function resulting from all splits that use this covariate.</p></dd>

</dl></div>
    <div id="references">
    <h2>References</h2>
    <p>Breiman L, Friedman JH, Olshen RA, Stone CJ (2017).
<em>Classification And Regression Trees</em>.
Routledge.
ISBN 9781315139470, <a href="https://doi.org/10.1201/9781315139470" class="external-link">doi:10.1201/9781315139470</a>
.<br><br> Ćevid D, Bühlmann P, Meinshausen N (2020).
“Spectral Deconfounding via Perturbed Sparse Linear Models.”
<em>J. Mach. Learn. Res.</em>, <b>21</b>(1).
ISSN 1532-4435, <a href="http://jmlr.org/papers/v21/19-545.html" class="external-link">http://jmlr.org/papers/v21/19-545.html</a>.<br><br> Guo Z, Ćevid D, Bühlmann P (2022).
“Doubly debiased lasso: High-dimensional inference under hidden confounding.”
<em>The Annals of Statistics</em>, <b>50</b>(3).
ISSN 0090-5364, <a href="https://doi.org/10.1214/21-AOS2152" class="external-link">doi:10.1214/21-AOS2152</a>
.<br><br> Paul D, Bair E, Hastie T, Tibshirani R (2008).
““Preconditioning” for feature selection and regression in high-dimensional problems.”
<em>The Annals of Statistics</em>, <b>36</b>(4).
ISSN 0090-5364, <a href="https://doi.org/10.1214/009053607000000578" class="external-link">doi:10.1214/009053607000000578</a>
.</p>
    </div>
    <div id="see-also">
    <h2>See also</h2>
    <div class="dont-index"><p><code><a href="simulate_data_nonlinear.html">simulate_data_nonlinear</a></code>, <code><a href="regPath.SDTree.html">regPath.SDTree</a></code>,
<code><a href="prune.SDTree.html">prune.SDTree</a></code>, <code><a href="partDependence.html">partDependence</a></code></p></div>
    </div>
    <div id="author">
    <h2>Author</h2>
    <p>Markus Ulmer</p>
    </div>

    <div id="ref-examples">
    <h2>Examples</h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">10</span></span></span>
<span class="r-in"><span><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span> <span class="op">*</span> <span class="fl">5</span><span class="op">)</span>, nrow <span class="op">=</span> <span class="va">n</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sign.html" class="external-link">sign</a></span><span class="op">(</span><span class="va">X</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span><span class="op">)</span> <span class="op">*</span> <span class="fl">3</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu">SDTree</span><span class="op">(</span>x <span class="op">=</span> <span class="va">X</span>, y <span class="op">=</span> <span class="va">y</span>, cp <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co">###### subset of predictors</span></span></span>
<span class="r-in"><span><span class="co"># if we know, that only the first covariate has an effect on y,</span></span></span>
<span class="r-in"><span><span class="co"># we can estimate only its effect and use the others just for deconfounding</span></span></span>
<span class="r-in"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu">SDTree</span><span class="op">(</span>x <span class="op">=</span> <span class="va">X</span>, y <span class="op">=</span> <span class="va">y</span>, cp <span class="op">=</span> <span class="fl">0.5</span>, predictors <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># \donttest{</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">42</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="co"># simulation of confounded data</span></span></span>
<span class="r-in"><span><span class="va">sim_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="simulate_data_step.html">simulate_data_step</a></span><span class="op">(</span>q <span class="op">=</span> <span class="fl">2</span>, p <span class="op">=</span> <span class="fl">15</span>, n <span class="op">=</span> <span class="fl">100</span>, m <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">X</span> <span class="op">&lt;-</span> <span class="va">sim_data</span><span class="op">$</span><span class="va">X</span></span></span>
<span class="r-in"><span><span class="va">Y</span> <span class="op">&lt;-</span> <span class="va">sim_data</span><span class="op">$</span><span class="va">Y</span></span></span>
<span class="r-in"><span><span class="va">train_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span><span class="va">X</span>, <span class="va">Y</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="co"># causal parents of y</span></span></span>
<span class="r-in"><span><span class="va">sim_data</span><span class="op">$</span><span class="va">j</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] 15  4</span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="va">tree_plain_cv</span> <span class="op">&lt;-</span> <span class="fu"><a href="cvSDTree.html">cvSDTree</a></span><span class="op">(</span><span class="va">Y</span> <span class="op">~</span> <span class="va">.</span>, <span class="va">train_data</span>, Q_type <span class="op">=</span> <span class="st">"no_deconfounding"</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">tree_plain</span> <span class="op">&lt;-</span> <span class="fu">SDTree</span><span class="op">(</span><span class="va">Y</span> <span class="op">~</span> <span class="va">.</span>, <span class="va">train_data</span>, Q_type <span class="op">=</span> <span class="st">"no_deconfounding"</span>, cp <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="va">tree_causal_cv</span> <span class="op">&lt;-</span> <span class="fu"><a href="cvSDTree.html">cvSDTree</a></span><span class="op">(</span><span class="va">Y</span> <span class="op">~</span> <span class="va">.</span>, <span class="va">train_data</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">tree_causal</span> <span class="op">&lt;-</span> <span class="fu">SDTree</span><span class="op">(</span>y <span class="op">=</span> <span class="va">Y</span>, x <span class="op">=</span> <span class="va">X</span>, cp <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># check regularization path of variable importance</span></span></span>
<span class="r-in"><span><span class="va">path</span> <span class="op">&lt;-</span> <span class="fu"><a href="regPath.SDForest.html">regPath</a></span><span class="op">(</span><span class="va">tree_causal</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">path</span><span class="op">)</span></span></span>
<span class="r-plt img"><img src="SDTree-1.png" alt="" width="700" height="433"></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="va">tree_plain</span> <span class="op">&lt;-</span> <span class="fu"><a href="prune.SDForest.html">prune</a></span><span class="op">(</span><span class="va">tree_plain</span>, cp <span class="op">=</span> <span class="va">tree_plain_cv</span><span class="op">$</span><span class="va">cp_min</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">tree_causal</span> <span class="op">&lt;-</span> <span class="fu"><a href="prune.SDForest.html">prune</a></span><span class="op">(</span><span class="va">tree_causal</span>, cp <span class="op">=</span> <span class="va">tree_causal_cv</span><span class="op">$</span><span class="va">cp_min</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">tree_causal</span><span class="op">)</span></span></span>
<span class="r-plt img"><img src="SDTree-2.png" alt="" width="700" height="433"></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">tree_plain</span><span class="op">)</span></span></span>
<span class="r-plt img"><img src="SDTree-3.png" alt="" width="700" height="433"></span>
<span class="r-in"><span><span class="co"># }</span></span></span>
</code></pre></div>
    </div>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">
    <nav id="toc" data-toggle="toc" class="sticky-top"><h2 data-toc-skip>Contents</h2>
    </nav></div>
</div>


      <footer><div class="copyright">
  <p></p><p>Developed by <a href="https://www.markus-ulmer.ch" class="external-link">Markus Ulmer</a>, Cyrill Scheidegger.</p>
</div>

<div class="pkgdown">
  <p></p><p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.2.0.</p>
</div>

      </footer></div>






  </body></html>

